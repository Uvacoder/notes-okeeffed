{"expireTime":9007200849425545000,"key":"gatsby-plugin-mdx-entire-payload-5a8c00c59cb9f17df1681bc1185a1f76-","val":{"mdast":{"type":"root","children":[{"type":"import","value":"import DefaultLayout from \"/Users/dennis.okeeffe/Project-Imposter/developer-notes/node_modules/gatsby-theme-docz/src/base/Layout.js\"","position":{"start":{"line":3,"column":1,"offset":2},"end":{"line":3,"column":133,"offset":134},"indent":[]}},{"type":"export","default":true,"value":"export default DefaultLayout","position":{"start":{"line":5,"column":1,"offset":136},"end":{"line":5,"column":29,"offset":164},"indent":[]}},{"type":"heading","depth":1,"children":[{"type":"text","value":"Hello Kafka","position":{"start":{"line":8,"column":3,"offset":169},"end":{"line":8,"column":14,"offset":180},"indent":[]}}],"position":{"start":{"line":8,"column":1,"offset":167},"end":{"line":8,"column":14,"offset":180},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Resources","position":{"start":{"line":10,"column":4,"offset":185},"end":{"line":10,"column":13,"offset":194},"indent":[]}}],"position":{"start":{"line":10,"column":1,"offset":182},"end":{"line":10,"column":13,"offset":194},"indent":[]}},{"type":"list","ordered":true,"start":1,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"link","title":null,"url":"https://medium.com/big-data-engineering/hello-kafka-world-the-complete-guide-to-kafka-with-docker-and-python-f788e2588cfc","children":[{"type":"text","value":"Getting started with Kafka","position":{"start":{"line":12,"column":5,"offset":200},"end":{"line":12,"column":31,"offset":226},"indent":[]}}],"position":{"start":{"line":12,"column":4,"offset":199},"end":{"line":12,"column":155,"offset":350},"indent":[]}}],"position":{"start":{"line":12,"column":4,"offset":199},"end":{"line":12,"column":155,"offset":350},"indent":[]}}],"position":{"start":{"line":12,"column":1,"offset":196},"end":{"line":12,"column":155,"offset":350},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"link","title":null,"url":"https://github.com/SOHU-Co/kafka-node","children":[{"type":"text","value":"Kafka Node Github","position":{"start":{"line":13,"column":5,"offset":355},"end":{"line":13,"column":22,"offset":372},"indent":[]}}],"position":{"start":{"line":13,"column":4,"offset":354},"end":{"line":13,"column":62,"offset":412},"indent":[]}}],"position":{"start":{"line":13,"column":4,"offset":354},"end":{"line":13,"column":62,"offset":412},"indent":[]}}],"position":{"start":{"line":13,"column":1,"offset":351},"end":{"line":13,"column":62,"offset":412},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"link","title":null,"url":"https://github.com/wurstmeister/kafka-docker","children":[{"type":"text","value":"Original Kafka Docker Github","position":{"start":{"line":14,"column":5,"offset":417},"end":{"line":14,"column":33,"offset":445},"indent":[]}}],"position":{"start":{"line":14,"column":4,"offset":416},"end":{"line":14,"column":80,"offset":492},"indent":[]}}],"position":{"start":{"line":14,"column":4,"offset":416},"end":{"line":14,"column":80,"offset":492},"indent":[]}}],"position":{"start":{"line":14,"column":1,"offset":413},"end":{"line":14,"column":80,"offset":492},"indent":[]}}],"position":{"start":{"line":12,"column":1,"offset":196},"end":{"line":14,"column":80,"offset":492},"indent":[1,1]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Getting Started with Nodejs","position":{"start":{"line":16,"column":4,"offset":497},"end":{"line":16,"column":31,"offset":524},"indent":[]}}],"position":{"start":{"line":16,"column":1,"offset":494},"end":{"line":16,"column":31,"offset":524},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Run ","position":{"start":{"line":18,"column":1,"offset":526},"end":{"line":18,"column":5,"offset":530},"indent":[]}},{"type":"inlineCode","value":"git clone https://github.com/wurstmeister/kafka-docker.git","position":{"start":{"line":18,"column":5,"offset":530},"end":{"line":18,"column":65,"offset":590},"indent":[]}},{"type":"text","value":" to clone wurstmeister's repo.","position":{"start":{"line":18,"column":65,"offset":590},"end":{"line":18,"column":95,"offset":620},"indent":[]}}],"position":{"start":{"line":18,"column":1,"offset":526},"end":{"line":18,"column":95,"offset":620},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Prerequisites","position":{"start":{"line":20,"column":4,"offset":625},"end":{"line":20,"column":17,"offset":638},"indent":[]}}],"position":{"start":{"line":20,"column":1,"offset":622},"end":{"line":20,"column":17,"offset":638},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Make sure you have both Docker and Docker Compose installed.","position":{"start":{"line":22,"column":1,"offset":640},"end":{"line":22,"column":61,"offset":700},"indent":[]}}],"position":{"start":{"line":22,"column":1,"offset":640},"end":{"line":22,"column":61,"offset":700},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Docker Composing","position":{"start":{"line":24,"column":4,"offset":705},"end":{"line":24,"column":20,"offset":721},"indent":[]}}],"position":{"start":{"line":24,"column":1,"offset":702},"end":{"line":24,"column":20,"offset":721},"indent":[]}},{"type":"code","lang":"shell","meta":null,"value":"docker-compose up -d\ndocker-compose scale kafka=3\n# to see processes\ndocker-compose ps\n# teardown\ndocker-compose stop","position":{"start":{"line":26,"column":1,"offset":723},"end":{"line":33,"column":4,"offset":853},"indent":[1,1,1,1,1,1,1]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Consume/Producing from within Docker Container","position":{"start":{"line":35,"column":4,"offset":858},"end":{"line":35,"column":50,"offset":904},"indent":[]}}],"position":{"start":{"line":35,"column":1,"offset":855},"end":{"line":35,"column":50,"offset":904},"indent":[]}},{"type":"code","lang":"shell","meta":null,"value":"# from your terminal run:\ndocker exec -i -t -u root $(docker ps | grep docker_kafka | cut -d' ' -f1) /bin/bash\n# $(docker ps | grep docker_kafka | cut -d' ' -f1) - Will return the docker process ID of the Kafka Docker running so you can access it\n\n# create topic1 and topic2 for our examples\n$KAFKA_HOME/bin/kafka-topics.sh --create --partitions 4 --bootstrap-server localhost:9092 --topic topic1\n$KAFKA_HOME/bin/kafka-topics.sh --create --partitions 4 --bootstrap-server localhost:9092 --topic topic2\n\n# optional: create a consumer\n$KAFKA_HOME/bin/kafka-console-consumer.sh --from-beginning --bootstrap-server localhost:9092 --topic=topic1\n\n# optional: create a producer\n$KAFKA_HOME/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic=topic1","position":{"start":{"line":37,"column":1,"offset":906},"end":{"line":51,"column":4,"offset":1676},"indent":[1,1,1,1,1,1,1,1,1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"Note: We use ","position":{"start":{"line":53,"column":1,"offset":1678},"end":{"line":53,"column":14,"offset":1691},"indent":[]}},{"type":"inlineCode","value":"localhost:9092","position":{"start":{"line":53,"column":14,"offset":1691},"end":{"line":53,"column":30,"offset":1707},"indent":[]}},{"type":"text","value":" here instead of ","position":{"start":{"line":53,"column":30,"offset":1707},"end":{"line":53,"column":47,"offset":1724},"indent":[]}},{"type":"inlineCode","value":"kafka:9092","position":{"start":{"line":53,"column":47,"offset":1724},"end":{"line":53,"column":59,"offset":1736},"indent":[]}},{"type":"text","value":" for our Node Kafka scripts.","position":{"start":{"line":53,"column":59,"offset":1736},"end":{"line":53,"column":87,"offset":1764},"indent":[]}}],"position":{"start":{"line":53,"column":1,"offset":1678},"end":{"line":53,"column":87,"offset":1764},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"When sending messages as a producer, note that we are latching onto particular partitions in the Node app and so only messages that head to a particular partition will be consumed.","position":{"start":{"line":55,"column":1,"offset":1766},"end":{"line":55,"column":181,"offset":1946},"indent":[]}}],"position":{"start":{"line":55,"column":1,"offset":1766},"end":{"line":55,"column":181,"offset":1946},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Node Kafka","position":{"start":{"line":57,"column":4,"offset":1951},"end":{"line":57,"column":14,"offset":1961},"indent":[]}}],"position":{"start":{"line":57,"column":1,"offset":1948},"end":{"line":57,"column":14,"offset":1961},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Start a new project and install and prep the files we need:","position":{"start":{"line":59,"column":1,"offset":1963},"end":{"line":59,"column":60,"offset":2022},"indent":[]}}],"position":{"start":{"line":59,"column":1,"offset":1963},"end":{"line":59,"column":60,"offset":2022},"indent":[]}},{"type":"code","lang":"shell","meta":null,"value":"yarn init -y\nyarn add node-kafka\ntouch consumer.js producer.js","position":{"start":{"line":61,"column":1,"offset":2024},"end":{"line":65,"column":4,"offset":2099},"indent":[1,1,1,1]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Producer","position":{"start":{"line":67,"column":4,"offset":2104},"end":{"line":67,"column":12,"offset":2112},"indent":[]}}],"position":{"start":{"line":67,"column":1,"offset":2101},"end":{"line":67,"column":12,"offset":2112},"indent":[]}},{"type":"code","lang":"javascript","meta":null,"value":"var kafka = require('kafka-node'),\n  Producer = kafka.Producer,\n  KeyedMessage = kafka.KeyedMessage,\n  client = new kafka.KafkaClient(),\n  producer = new Producer(client),\n  km = new KeyedMessage('key', 'message'),\n  payloads = [\n    { topic: 'topic1', messages: 'hi', partition: 0 },\n    { topic: 'topic2', messages: ['hello', 'world', km] },\n  ];\nproducer.on('ready', function() {\n  producer.send(payloads, function(err, data) {\n    console.log(data);\n  });\n});\n\nproducer.on('error', function(err) {});","position":{"start":{"line":69,"column":1,"offset":2114},"end":{"line":87,"column":4,"offset":2636},"indent":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Consumer","position":{"start":{"line":89,"column":4,"offset":2641},"end":{"line":89,"column":12,"offset":2649},"indent":[]}}],"position":{"start":{"line":89,"column":1,"offset":2638},"end":{"line":89,"column":12,"offset":2649},"indent":[]}},{"type":"code","lang":"javascript","meta":null,"value":"var kafka = require('kafka-node'),\n  Consumer = kafka.Consumer,\n  client = new kafka.KafkaClient(),\n  consumer = new Consumer(\n    client,\n    [{ topic: 'topic1', partition: 0 }, { topic: 'topic2', partition: 1 }],\n    {\n      autoCommit: false,\n    },\n  );","position":{"start":{"line":91,"column":1,"offset":2651},"end":{"line":102,"column":4,"offset":2926},"indent":[1,1,1,1,1,1,1,1,1,1,1]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"Running it altogether","position":{"start":{"line":104,"column":4,"offset":2931},"end":{"line":104,"column":25,"offset":2952},"indent":[]}}],"position":{"start":{"line":104,"column":1,"offset":2928},"end":{"line":104,"column":25,"offset":2952},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Ensure that you've created ","position":{"start":{"line":106,"column":1,"offset":2954},"end":{"line":106,"column":28,"offset":2981},"indent":[]}},{"type":"inlineCode","value":"topic1","position":{"start":{"line":106,"column":28,"offset":2981},"end":{"line":106,"column":36,"offset":2989},"indent":[]}},{"type":"text","value":" and ","position":{"start":{"line":106,"column":36,"offset":2989},"end":{"line":106,"column":41,"offset":2994},"indent":[]}},{"type":"inlineCode","value":"topic2","position":{"start":{"line":106,"column":41,"offset":2994},"end":{"line":106,"column":49,"offset":3002},"indent":[]}},{"type":"text","value":" from within the Docker container.","position":{"start":{"line":106,"column":49,"offset":3002},"end":{"line":106,"column":83,"offset":3036},"indent":[]}}],"position":{"start":{"line":106,"column":1,"offset":2954},"end":{"line":106,"column":83,"offset":3036},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Once created, we can run ","position":{"start":{"line":108,"column":1,"offset":3038},"end":{"line":108,"column":26,"offset":3063},"indent":[]}},{"type":"inlineCode","value":"node consumer.js","position":{"start":{"line":108,"column":26,"offset":3063},"end":{"line":108,"column":44,"offset":3081},"indent":[]}},{"type":"text","value":" in one terminal to listen for those topics on particular partitions and ","position":{"start":{"line":108,"column":44,"offset":3081},"end":{"line":108,"column":117,"offset":3154},"indent":[]}},{"type":"inlineCode","value":"node producer.js","position":{"start":{"line":108,"column":117,"offset":3154},"end":{"line":108,"column":135,"offset":3172},"indent":[]}},{"type":"text","value":" to fire off some notifications.","position":{"start":{"line":108,"column":135,"offset":3172},"end":{"line":108,"column":167,"offset":3204},"indent":[]}}],"position":{"start":{"line":108,"column":1,"offset":3038},"end":{"line":108,"column":167,"offset":3204},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"All the received events on the consumer will then log to the terminal.","position":{"start":{"line":110,"column":1,"offset":3206},"end":{"line":110,"column":71,"offset":3276},"indent":[]}}],"position":{"start":{"line":110,"column":1,"offset":3206},"end":{"line":110,"column":71,"offset":3276},"indent":[]}},{"type":"export","value":"export const _frontmatter = {}","position":{"start":{"line":113,"column":1,"offset":3279},"end":{"line":113,"column":31,"offset":3309},"indent":[]}}],"position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":113,"column":31,"offset":3309}}},"scopeImports":[],"scopeIdentifiers":[],"rawMDXOutput":"/* @jsx mdx */\nimport { mdx } from '@mdx-js/react';\n/* @jsx mdx */\nimport DefaultLayout from \"/Users/dennis.okeeffe/Project-Imposter/developer-notes/node_modules/gatsby-theme-docz/src/base/Layout.js\"\nexport const _frontmatter = {};\nconst makeShortcode = name => function MDXDefaultShortcode(props) {\n  console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\")\n  return <div {...props}/>\n};\n\nconst layoutProps = {\n  _frontmatter\n};\nconst MDXLayout = DefaultLayout\nexport default function MDXContent({\n  components,\n  ...props\n}) {\n  return <MDXLayout {...layoutProps} {...props} components={components} mdxType=\"MDXLayout\">\n\n\n    <h1 {...{\n      \"id\": \"hello-kafka\"\n    }}>{`Hello Kafka`}</h1>\n    <h2 {...{\n      \"id\": \"resources\"\n    }}>{`Resources`}</h2>\n    <ol>\n      <li parentName=\"ol\"><a parentName=\"li\" {...{\n          \"href\": \"https://medium.com/big-data-engineering/hello-kafka-world-the-complete-guide-to-kafka-with-docker-and-python-f788e2588cfc\"\n        }}>{`Getting started with Kafka`}</a></li>\n      <li parentName=\"ol\"><a parentName=\"li\" {...{\n          \"href\": \"https://github.com/SOHU-Co/kafka-node\"\n        }}>{`Kafka Node Github`}</a></li>\n      <li parentName=\"ol\"><a parentName=\"li\" {...{\n          \"href\": \"https://github.com/wurstmeister/kafka-docker\"\n        }}>{`Original Kafka Docker Github`}</a></li>\n    </ol>\n    <h2 {...{\n      \"id\": \"getting-started-with-nodejs\"\n    }}>{`Getting Started with Nodejs`}</h2>\n    <p>{`Run `}<inlineCode parentName=\"p\">{`git clone https://github.com/wurstmeister/kafka-docker.git`}</inlineCode>{` to clone wurstmeister's repo.`}</p>\n    <h2 {...{\n      \"id\": \"prerequisites\"\n    }}>{`Prerequisites`}</h2>\n    <p>{`Make sure you have both Docker and Docker Compose installed.`}</p>\n    <h2 {...{\n      \"id\": \"docker-composing\"\n    }}>{`Docker Composing`}</h2>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-shell\"\n      }}>{`docker-compose up -d\ndocker-compose scale kafka=3\n# to see processes\ndocker-compose ps\n# teardown\ndocker-compose stop\n`}</code></pre>\n    <h2 {...{\n      \"id\": \"consumeproducing-from-within-docker-container\"\n    }}>{`Consume/Producing from within Docker Container`}</h2>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-shell\"\n      }}>{`# from your terminal run:\ndocker exec -i -t -u root $(docker ps | grep docker_kafka | cut -d' ' -f1) /bin/bash\n# $(docker ps | grep docker_kafka | cut -d' ' -f1) - Will return the docker process ID of the Kafka Docker running so you can access it\n\n# create topic1 and topic2 for our examples\n$KAFKA_HOME/bin/kafka-topics.sh --create --partitions 4 --bootstrap-server localhost:9092 --topic topic1\n$KAFKA_HOME/bin/kafka-topics.sh --create --partitions 4 --bootstrap-server localhost:9092 --topic topic2\n\n# optional: create a consumer\n$KAFKA_HOME/bin/kafka-console-consumer.sh --from-beginning --bootstrap-server localhost:9092 --topic=topic1\n\n# optional: create a producer\n$KAFKA_HOME/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic=topic1\n`}</code></pre>\n    <p>{`Note: We use `}<inlineCode parentName=\"p\">{`localhost:9092`}</inlineCode>{` here instead of `}<inlineCode parentName=\"p\">{`kafka:9092`}</inlineCode>{` for our Node Kafka scripts.`}</p>\n    <p>{`When sending messages as a producer, note that we are latching onto particular partitions in the Node app and so only messages that head to a particular partition will be consumed.`}</p>\n    <h2 {...{\n      \"id\": \"node-kafka\"\n    }}>{`Node Kafka`}</h2>\n    <p>{`Start a new project and install and prep the files we need:`}</p>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-shell\"\n      }}>{`yarn init -y\nyarn add node-kafka\ntouch consumer.js producer.js\n`}</code></pre>\n    <h2 {...{\n      \"id\": \"producer\"\n    }}>{`Producer`}</h2>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-javascript\"\n      }}>{`var kafka = require('kafka-node'),\n  Producer = kafka.Producer,\n  KeyedMessage = kafka.KeyedMessage,\n  client = new kafka.KafkaClient(),\n  producer = new Producer(client),\n  km = new KeyedMessage('key', 'message'),\n  payloads = [\n    { topic: 'topic1', messages: 'hi', partition: 0 },\n    { topic: 'topic2', messages: ['hello', 'world', km] },\n  ];\nproducer.on('ready', function() {\n  producer.send(payloads, function(err, data) {\n    console.log(data);\n  });\n});\n\nproducer.on('error', function(err) {});\n`}</code></pre>\n    <h2 {...{\n      \"id\": \"consumer\"\n    }}>{`Consumer`}</h2>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-javascript\"\n      }}>{`var kafka = require('kafka-node'),\n  Consumer = kafka.Consumer,\n  client = new kafka.KafkaClient(),\n  consumer = new Consumer(\n    client,\n    [{ topic: 'topic1', partition: 0 }, { topic: 'topic2', partition: 1 }],\n    {\n      autoCommit: false,\n    },\n  );\n`}</code></pre>\n    <h2 {...{\n      \"id\": \"running-it-altogether\"\n    }}>{`Running it altogether`}</h2>\n    <p>{`Ensure that you've created `}<inlineCode parentName=\"p\">{`topic1`}</inlineCode>{` and `}<inlineCode parentName=\"p\">{`topic2`}</inlineCode>{` from within the Docker container.`}</p>\n    <p>{`Once created, we can run `}<inlineCode parentName=\"p\">{`node consumer.js`}</inlineCode>{` in one terminal to listen for those topics on particular partitions and `}<inlineCode parentName=\"p\">{`node producer.js`}</inlineCode>{` to fire off some notifications.`}</p>\n    <p>{`All the received events on the consumer will then log to the terminal.`}</p>\n\n    </MDXLayout>;\n}\n\n;\nMDXContent.isMDXComponent = true;"}}