{"version":3,"sources":["webpack:///../manual/Machine-Learning/ML-Decision-Trees.md"],"names":["_frontmatter","layoutProps","MDXLayout","DefaultLayout","MDXContent","components","props","mdxType","parentName","isMDXComponent"],"mappings":"ofAMO,IAAMA,EAAe,Q,8NAE5B,IAKMC,EAAc,CAClBD,gBAEIE,EAAYC,IACH,SAASC,EAAT,GAGZ,IAFDC,EAEC,EAFDA,WACGC,E,oIACF,mBACD,OAAO,YAACJ,EAAD,KAAeD,EAAiBK,EAAhC,CAAuCD,WAAYA,EAAYE,QAAQ,cAG5E,iBAAQ,CACN,GAAM,kBADR,kBAMA,sBACE,kBAAIC,WAAW,MAAK,mBAAGA,WAAW,MAAS,CACvC,KAAQ,oBADQ,kBAEO,kBAAIA,WAAW,MACtC,kBAAIA,WAAW,MAAK,mBAAGA,WAAW,MAAS,CACvC,KAAQ,eADQ,cAGpB,kBAAIA,WAAW,MAAK,mBAAGA,WAAW,MAAS,CACvC,KAAQ,wCADQ,0CAQ1B,iBAAQ,CACN,GAAM,aADR,aAGA,qBAAG,sBAAQA,WAAW,KAAnB,8CACH,4FACA,2FACA,uLACA,8HACA,+GACA,sGACA,8DACA,iIACA,qBAAG,sBAAQA,WAAW,KAAnB,cACH,oCAAmB,0BAAYA,WAAW,KAAvB,aAAnB,iDAA0H,0BAAYA,WAAW,KAAvB,cAA1H,4BAA6M,0BAAYA,WAAW,KAAvB,aAA7M,qCAAyS,0BAAYA,WAAW,KAAvB,cAAzS,KACA,iEAAgD,0BAAYA,WAAW,KAAvB,aAAhD,cAAoH,0BAAYA,WAAW,KAAvB,aAApH,oBAA8L,0BAAYA,WAAW,KAAvB,cAA9L,6BAAkR,0BAAYA,WAAW,KAAvB,aAAlR,oBAA4V,0BAAYA,WAAW,KAAvB,cAA5V,KACA,sHAAqG,0BAAYA,WAAW,KAAvB,KAArG,yEACA,kCAAiB,0BAAYA,WAAW,KAAvB,kCAAjB,KACA,uKACA,4KACA,iBAAQ,CACN,GAAM,sCADR,sCAGA,yQACA,2GACA,yIACA,mFACA,+EACA,uBAAK,sBAAMA,WAAW,OAAU,CAC5B,UAAa,oBADZ,0XAaL,sEACA,uBAAK,sBAAMA,WAAW,OAAU,CAC5B,UAAa,oBADZ,iOAUL,sOACA,8IACA,qBAAG,sBAAQA,WAAW,KAAnB,+CACH,iI,qNAKJJ,EAAWK,gBAAiB","file":"component---manual-machine-learning-ml-decision-trees-md-bc1f4b3a59d2f3b26e4d.js","sourcesContent":["import React from 'react'\n  /* @jsx mdx */\nimport { mdx } from '@mdx-js/react';\n/* @jsx mdx */\n\nimport DefaultLayout from \"/Users/dennis.okeeffe/Project-Imposter/developer-notes/node_modules/gatsby-theme-docz/src/base/Layout.js\";\nexport const _frontmatter = {};\n\nconst makeShortcode = name => function MDXDefaultShortcode(props) {\n  console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n  return <div {...props} />;\n};\n\nconst layoutProps = {\n  _frontmatter\n};\nconst MDXLayout = DefaultLayout;\nexport default function MDXContent({\n  components,\n  ...props\n}) {\n  return <MDXLayout {...layoutProps} {...props} components={components} mdxType=\"MDXLayout\">\n\n\n    <h1 {...{\n      \"id\": \"decision-trees\"\n    }}>{`Decision Trees`}</h1>\n    {\n      /* TOC */\n    }\n    <ul>\n      <li parentName=\"ul\"><a parentName=\"li\" {...{\n          \"href\": \"#decision-trees\"\n        }}>{`Decision Trees`}</a><ul parentName=\"li\">\n          <li parentName=\"ul\"><a parentName=\"li\" {...{\n              \"href\": \"#intuition\"\n            }}>{`Intuition`}</a></li>\n          <li parentName=\"ul\"><a parentName=\"li\" {...{\n              \"href\": \"#decision-tree-regression-in-python\"\n            }}>{`Decision Tree Regression in Python`}</a></li>\n        </ul></li>\n    </ul>\n    {\n      /* /TOC */\n    }\n    <h2 {...{\n      \"id\": \"intuition\"\n    }}>{`Intuition`}</h2>\n    <p><strong parentName=\"p\">{`CART: Classification and Regression Trees`}</strong></p>\n    <p>{`We speak about both types, but for now - focus on regression trees.`}</p>\n    <p>{`Regression trees are a bit more complex than classification trees.`}</p>\n    <p>{`Imagine a scatter plot with two IV and we are predicting an DV y (which you wouldn't be able to see on the chart). Essentially the DV would sit on the z axis.`}</p>\n    <p>{`Once you run the regression decision tree algorithm, the scatter plot will be split up into segments.`}</p>\n    <p>{`For example, x1 might be split at 20. Another split may happen for x2 at 170, 200 etc.`}</p>\n    <p>{`The question, are the splits adding value to way we want to group our points?`}</p>\n    <p>{`Each split itself is known as a leaf.`}</p>\n    <p>{`The algorithm can handle mathematical issues and we can focus on the practical element of the algorithm.`}</p>\n    <p><strong parentName=\"p\">{`Splitting`}</strong></p>\n    <p>{`If we split `}<inlineCode parentName=\"p\">{`x[1] < 20`}</inlineCode>{`, we have two options (y/N). If we then split `}<inlineCode parentName=\"p\">{`x[2] < 170`}</inlineCode>{`, we add a child node to `}<inlineCode parentName=\"p\">{`x[1] < 20`}</inlineCode>{` that checks y/N. If we then set \\``}<inlineCode parentName=\"p\">{`x[2] < 200`}</inlineCode>{`.`}</p>\n    <p>{`After having a two child tree, if we set `}<inlineCode parentName=\"p\">{`x[1] < 40`}</inlineCode>{` such that `}<inlineCode parentName=\"p\">{`x[1] < 20`}</inlineCode>{` is not true and `}<inlineCode parentName=\"p\">{`x[2] < 170`}</inlineCode>{` is true, we can then set `}<inlineCode parentName=\"p\">{`x[1] < 40`}</inlineCode>{` as the child to `}<inlineCode parentName=\"p\">{`x[2] < 170`}</inlineCode>{`.`}</p>\n    <p>{`Once we start this tree, what do we populate into those boxes? Well, we decide how we predict `}<inlineCode parentName=\"p\">{`y`}</inlineCode>{` with a new observation added to the plane x`}{`[1]`}{` and x`}{`[2]`}{`.`}</p>\n    <p>{`Key note: `}<inlineCode parentName=\"p\">{`Adding splits adds information`}</inlineCode>{`.`}</p>\n    <p>{`What we do is that for each terminal leaf, we take the average and assign the value that we give to any new element that falls into that leaf.`}</p>\n    <p>{`Now, if we have a new value, we check the decision tree where it falls and then assign the new element the value of where it falls as a prediction.`}</p>\n    <h2 {...{\n      \"id\": \"decision-tree-regression-in-python\"\n    }}>{`Decision Tree Regression in Python`}</h2>\n    <p>{`Warning for the decision tree, because we need to consider the entropy and split the result into data points. If we stick to one dimension, how do we have a line that is not horizontal? If the splits are made, they should remain a constant.`}</p>\n    <p>{`Either the intervals are infinite (which they are not), or the model has an issue.`}</p>\n    <p>{`The reason the issue came up, is because of what we have used to create the plot since this is no longer linear.`}</p>\n    <p>{`This is now a non-linear, non-continuous regression model.`}</p>\n    <p>{`What is the best way to view something non-continuous?`}</p>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`# Visualising the Decision Tree results\nX_grid = np.arange(min(X), max(X), 0.01)\nX_grid = X_grid.reshape(len(X_grid), 1)\nplt.scatter(X, y, color = 'red')\nplt.plot(X_grid, regressor.predict(X_grid), color = 'blue')\nplt.title('Truth or Bluff (Decision Tree Regression)')\nplt.xlabel('Position level')\nplt.ylabel('Salary')\nplt.savefig('decision-tree.png')\nplt.show()\n`}</code></pre>\n    <p>{`As for getting the decision tree code to run:`}</p>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`# Prediciting the Decision Tree results\n# Create the Regressor\nfrom sklearn.tree import DecisionTreeRegressor\nregressor = DecisionTreeRegressor(random_state=0)\nregressor.fit(X, y)\n\ny_pred = regressor.predict(6.5)\n`}</code></pre>\n    <p>{`Ensure you have a higher resolution in order to visualize the splits. Given that the example in the tutorial has just 1 DV and 1 IV, it will come out like steps as the only splits will occur on the x axis.`}</p>\n    <p>{`The model itself is not necessarily that interesting in 1D, but over many dimensions it becomes far more interesting.`}</p>\n    <p><strong parentName=\"p\">{`What happens when you use a random forest?`}</strong></p>\n    <p>{`A Random Forest is a team of decision trees. What happens with a team of 10 trees? 50 trees? 500 trees?`}</p>\n\n    </MDXLayout>;\n}\n;\nMDXContent.isMDXComponent = true;\n      "],"sourceRoot":""}