{"componentChunkName":"component---manual-machine-learning-ml-udemy-md","path":"/manual-machine-learning-ml-udemy","result":{"pageContext":{"frontmatter":{"name":"ML Udemy","menu":"Machine Learning"},"entry":{"id":"692cceb0e4d863c4b39bb8438857cf48","filepath":"manual/Machine-Learning/ML-Udemy.md","fullpath":"/Users/dennis.okeeffe/Project-Imposter/developer-notes/manual/Machine-Learning/ML-Udemy.md","route":"/manual-machine-learning-ml-udemy","slug":"manual-machine-learning-ml-udemy","name":"ML Udemy","menu":"Machine Learning","headings":[{"slug":"machine-learning---udemy-a-z","depth":1,"value":"Machine Learning - Udemy A-Z"},{"slug":"part-1---data-preprocessing","depth":2,"value":"Part 1 - Data Preprocessing"},{"slug":"1-the-initial-data","depth":2,"value":"1. The initial data"},{"slug":"importing-the-libraries","depth":3,"value":"Importing the Libraries"},{"slug":"importing-the-dataset","depth":3,"value":"Importing the Dataset"},{"slug":"missing-data","depth":3,"value":"Missing Data"},{"slug":"catagorical-variables","depth":3,"value":"Catagorical Variables"},{"slug":"splitting-the-data-into-a-training-set-and-test-set","depth":3,"value":"Splitting the data into a Training Set and Test Set"},{"slug":"feature-scaling","depth":3,"value":"Feature Scaling"},{"slug":"templating-data-preprocessing","depth":3,"value":"Templating Data Preprocessing"},{"slug":"2-regression","depth":2,"value":"2. Regression"},{"slug":"21-simple-linear-regression","depth":2,"value":"2.1: Simple Linear Regression"},{"slug":"intuition","depth":3,"value":"Intuition"},{"slug":"in-python","depth":3,"value":"IN PYTHON"},{"slug":"22-multiple-linear-regression","depth":2,"value":"2.2 Multiple Linear Regression"},{"slug":"intuition-1","depth":3,"value":"Intuition"},{"slug":"how-to-build-mlr-models-step-by-step","depth":3,"value":"How to build MLR models (step-by-step)"},{"slug":"in-python-1","depth":3,"value":"IN PYTHON"},{"slug":"backward-elimination---multiple-linear-regression","depth":3,"value":"Backward Elimination - Multiple Linear Regression"},{"slug":"23-polynomial-linear-regression","depth":2,"value":"2.3 Polynomial Linear Regression"},{"slug":"interpretation","depth":3,"value":"Interpretation"},{"slug":"24-support-vector-regression","depth":2,"value":"2.4 Support Vector Regression"},{"slug":"3-classification","depth":2,"value":"3. Classification"},{"slug":"31-logistical-regression","depth":3,"value":"3.1 Logistical Regression"},{"slug":"fitting-lr-to-the-training-set","depth":4,"value":"Fitting LR to the training set"},{"slug":"making-the-prediction","depth":4,"value":"Making the prediction"},{"slug":"investigating-the-confusion-matrix","depth":4,"value":"Investigating the confusion matrix"},{"slug":"visualising-the-results","depth":4,"value":"Visualising the results"},{"slug":"32-k-nearest-neighbours-algorith","depth":2,"value":"3.2 K-Nearest Neighbours Algorith"},{"slug":"intuition-2","depth":3,"value":"Intuition"},{"slug":"k-nn-in-python","depth":3,"value":"K-NN in Python"},{"slug":"final-code","depth":4,"value":"Final Code"},{"slug":"33-support-vector-machine-svm","depth":2,"value":"3.3 Support Vector Machine (SVM)"},{"slug":"svm-intuition","depth":3,"value":"SVM Intuition"},{"slug":"svm-in-python","depth":3,"value":"SVM in Python"},{"slug":"34-kernel-svm","depth":2,"value":"3.4 Kernel SVM"},{"slug":"kernel-svm-intuition","depth":3,"value":"Kernel SVM Intuition"},{"slug":"mapping-to-a-higher-dimension","depth":4,"value":"Mapping to a higher dimension"},{"slug":"the-kernel-trick","depth":4,"value":"The Kernel trick"},{"slug":"types-of-kernal-functions","depth":4,"value":"Types of Kernal Functions"},{"slug":"kernel-svm-example","depth":3,"value":"Kernel SVM Example"},{"slug":"35-naive-bayes","depth":2,"value":"3.5 Naive Bayes"},{"slug":"bayes-theorem","depth":3,"value":"Bayes Theorem"},{"slug":"naive-bayes-intuition","depth":3,"value":"Naive Bayes Intuition"},{"slug":"naive-bayes-example","depth":3,"value":"Naive Bayes Example"},{"slug":"36-decision-trees-classification","depth":2,"value":"3.6 Decision Trees Classification"},{"slug":"decision-tree-intuition","depth":3,"value":"Decision Tree Intuition"},{"slug":"decision-tree-classification-example","depth":3,"value":"Decision Tree Classification example"},{"slug":"37-random-forest-classification","depth":2,"value":"3.7 Random Forest Classification"},{"slug":"random-forest-intuition","depth":3,"value":"Random Forest Intuition"},{"slug":"random-forest-classification-example","depth":3,"value":"Random Forest Classification Example"},{"slug":"38-evaluating-classification-model-performance","depth":2,"value":"3.8 Evaluating Classification Model Performance"},{"slug":"false-positives-and-false-negatives","depth":3,"value":"False Positives and False Negatives"},{"slug":"confusion-matrix","depth":3,"value":"Confusion matrix"},{"slug":"accuracy-paradox","depth":3,"value":"Accuracy Paradox"},{"slug":"cumulative-accuracy-profile-cap","depth":3,"value":"Cumulative Accuracy Profile (CAP)"},{"slug":"cap-curve-analysis","depth":3,"value":"CAP Curve Analysis"},{"slug":"classification-summary","depth":2,"value":"Classification Summary"},{"slug":"how-do-i-know-which-model-to-choose-for-my-problem","depth":3,"value":"How do I know which model to choose for my problem?"},{"slug":"how-can-i-improve-each-of-these-models","depth":3,"value":"How can I improve each of these models?"},{"slug":"4-clustering","depth":2,"value":"4. Clustering"},{"slug":"41-k-means-clustering","depth":2,"value":"4.1 K-Means Clustering"},{"slug":"k-means-clustering-intuition","depth":3,"value":"K-Means Clustering Intuition"},{"slug":"k-means-random-initialization-trap","depth":3,"value":"K-Means Random Initialization Trap"},{"slug":"choosing-the-right-number-of-clusters","depth":3,"value":"Choosing the right number of clusters"},{"slug":"k-means-clustering-example","depth":3,"value":"K-Means Clustering Example"},{"slug":"42-hierarchichal-clustering","depth":2,"value":"4.2 Hierarchichal Clustering"},{"slug":"hc-intuition","depth":3,"value":"HC Intuition"},{"slug":"agglomerative-hc","depth":4,"value":"Agglomerative HC"},{"slug":"calculating-distance-between-clusters","depth":4,"value":"Calculating distance between clusters"},{"slug":"how-dendrograms-work","depth":3,"value":"How dendrograms work"},{"slug":"hc-using-dendrograms","depth":3,"value":"HC Using Dendrograms"},{"slug":"hc-example","depth":3,"value":"HC Example"},{"slug":"determining-optimum-clusters","depth":4,"value":"Determining optimum clusters"},{"slug":"hc-full-example","depth":3,"value":"HC Full example"},{"slug":"5-associate-rule-learning","depth":2,"value":"5. Associate Rule Learning"},{"slug":"51-apriori","depth":2,"value":"5.1 Apriori"},{"slug":"apriori-intuition","depth":3,"value":"Apriori Intuition"},{"slug":"steps","depth":4,"value":"Steps"},{"slug":"support","depth":4,"value":"Support"},{"slug":"confidence","depth":4,"value":"Confidence"},{"slug":"lift","depth":4,"value":"Lift"},{"slug":"apriori","depth":3,"value":"Apriori"},{"slug":"6-reinforcement-learning","depth":2,"value":"6. Reinforcement Learning"},{"slug":"61-upper-confidence-bound-ucb","depth":2,"value":"6.1 Upper Confidence Bound (UCB)"},{"slug":"the-multi-armed-bandit-problem","depth":3,"value":"The Multi-Armed Bandit Problem"},{"slug":"ucb-intuition","depth":3,"value":"UCB Intuition"},{"slug":"ucb-implementation-in-python","depth":3,"value":"UCB Implementation in Python"},{"slug":"implementing-ucb-by-scratch","depth":4,"value":"Implementing UCB by scratch"},{"slug":"62-thompson-sampling","depth":2,"value":"6.2 Thompson Sampling"},{"slug":"thompson-sampling-intuition","depth":3,"value":"Thompson Sampling Intuition"},{"slug":"bayesian-inference","depth":3,"value":"Bayesian Inference"},{"slug":"thompson-sampling-algorithm","depth":3,"value":"Thompson Sampling Algorithm"},{"slug":"algorithm-comparison-vs-ucb","depth":3,"value":"Algorithm Comparison vs UCB"},{"slug":"ucb-proscons","depth":4,"value":"UCB Pros/Cons"},{"slug":"thomspon-samples-proscons","depth":4,"value":"Thomspon Samples Pros/Cons"},{"slug":"implementing-the-algorithm","depth":3,"value":"Implementing the algorithm"},{"slug":"8-deep-learning","depth":2,"value":"8. Deep Learning"},{"slug":"81-artificial-neural-networks","depth":2,"value":"8.1 Artificial Neural Networks"},{"slug":"plan-of-attack","depth":3,"value":"Plan of attack"},{"slug":"the-neuron","depth":3,"value":"The Neuron"},{"slug":"activation-functions","depth":3,"value":"Activation functions"},{"slug":"threshold-function","depth":4,"value":"Threshold function"},{"slug":"sigmoid-function","depth":4,"value":"Sigmoid function"},{"slug":"rectifier-function","depth":4,"value":"Rectifier function"},{"slug":"hyperbolic-tangent-function-tanh","depth":4,"value":"Hyperbolic Tangent Function (tanh)"},{"slug":"how-do-nns-work","depth":3,"value":"How do NNs work?"},{"slug":"hidden-layer","depth":4,"value":"Hidden layer"},{"slug":"how-do-nns-learn","depth":3,"value":"How do NNs learn?"},{"slug":"gradient-descent","depth":3,"value":"Gradient descent"},{"slug":"stochastic-gradient-descent","depth":3,"value":"Stochastic Gradient Descent"},{"slug":"backpropagation","depth":3,"value":"Backpropagation"},{"slug":"training-the-ann-with-stochastic-gradient-descent","depth":3,"value":"Training the ANN with Stochastic Gradient Descent"},{"slug":"business-problem-description","depth":3,"value":"Business Problem Description"},{"slug":"installing-theano-tensorflow-and-keras","depth":3,"value":"Installing Theano, Tensorflow and Keras"},{"slug":"preparing-the-data-for-the-future-deep-learning-model","depth":3,"value":"Preparing the data for the future deep learning model"},{"slug":"building-the-ann","depth":3,"value":"Building the ANN"},{"slug":"82-convolutional-neural-networks","depth":2,"value":"8.2 Convolutional Neural Networks"},{"slug":"what-are-cnns","depth":3,"value":"What are CNNs"},{"slug":"convolution-operation","depth":3,"value":"Convolution Operation"},{"slug":"rectified-linear-unit-relu-layer","depth":3,"value":"Rectified Linear Unit (ReLU) Layer"},{"slug":"pooling","depth":3,"value":"Pooling"},{"slug":"flattening","depth":3,"value":"Flattening"},{"slug":"full-connection","depth":3,"value":"Full Connection"},{"slug":"summary","depth":3,"value":"Summary"},{"slug":"softmax-and-cross-entropy","depth":3,"value":"Softmax and Cross-Entropy"},{"slug":"cross-entropy-function","depth":4,"value":"Cross entropy function"},{"slug":"cnn-in-python","depth":3,"value":"CNN in Python"},{"slug":"9-dimensionality-reduction","depth":2,"value":"9. Dimensionality reduction"},{"slug":"91-principal-component-analysis---pca","depth":2,"value":"9.1 Principal Component Analysis - PCA"},{"slug":"pca-in-python","depth":3,"value":"PCA in Python"},{"slug":"confusion-matrix-1","depth":4,"value":"Confusion matrix"},{"slug":"code","depth":4,"value":"Code"},{"slug":"plot","depth":4,"value":"Plot"},{"slug":"92-linear-discriminant-analysis-lda","depth":2,"value":"9.2 Linear Discriminant Analysis (LDA)"},{"slug":"lda-intuition","depth":3,"value":"LDA Intuition"},{"slug":"steps-for-lda","depth":3,"value":"Steps for LDA"},{"slug":"lda-in-python","depth":3,"value":"LDA in Python"},{"slug":"93-kernal-pca","depth":2,"value":"9.3 Kernal PCA"},{"slug":"help-and-issue-tracking","depth":3,"value":"Help and Issue Tracking"}]}}}}