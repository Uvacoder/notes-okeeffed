{"version":3,"sources":["webpack:///../manual/Machine-Learning/ML-Random-Forest-Regression.md"],"names":["_frontmatter","layoutProps","MDXLayout","DefaultLayout","MDXContent","components","props","mdxType","parentName","isMDXComponent"],"mappings":"sfAMO,IAAMA,EAAe,Q,wOAE5B,IAKMC,EAAc,CAClBD,gBAEIE,EAAYC,IACH,SAASC,EAAT,GAGZ,IAFDC,EAEC,EAFDA,WACGC,E,oIACF,mBACD,OAAO,YAACJ,EAAD,KAAeD,EAAiBK,EAAhC,CAAuCD,WAAYA,EAAYE,QAAQ,cAG5E,iBAAQ,CACN,GAAM,4BADR,4BAGA,iBAAQ,CACN,GAAM,aADR,aAGA,yEACA,iHACA,qBAAG,sBAAQC,WAAW,KAAnB,UACH,sBACE,kBAAIA,WAAW,MAAf,uDACA,kBAAIA,WAAW,MAAf,8DACA,kBAAIA,WAAW,MAAf,gFACA,kBAAIA,WAAW,MAAf,gFAAqG,0BAAYA,WAAW,MAAvB,KAArG,uGAA2P,0BAAYA,WAAW,MAAvB,KAA3P,aAEF,0FACA,qBAAG,sBAAQA,WAAW,KAAnB,YACH,2PACA,kIACA,iBAAQ,CACN,GAAM,UADR,UAGA,wIACA,yHACA,iFACA,uBAAK,sBAAMA,WAAW,OAAU,CAC5B,UAAa,oBADZ,kMAQL,mHACA,qIACA,wIACA,iG,+NAKJJ,EAAWK,gBAAiB","file":"component---manual-machine-learning-ml-random-forest-regression-md-1007d544429f4b17098f.js","sourcesContent":["import React from 'react'\n  /* @jsx mdx */\nimport { mdx } from '@mdx-js/react';\n/* @jsx mdx */\n\nimport DefaultLayout from \"/Users/dennis.okeeffe/Project-Imposter/developer-notes/node_modules/gatsby-theme-docz/src/base/Layout.js\";\nexport const _frontmatter = {};\n\nconst makeShortcode = name => function MDXDefaultShortcode(props) {\n  console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n  return <div {...props} />;\n};\n\nconst layoutProps = {\n  _frontmatter\n};\nconst MDXLayout = DefaultLayout;\nexport default function MDXContent({\n  components,\n  ...props\n}) {\n  return <MDXLayout {...layoutProps} {...props} components={components} mdxType=\"MDXLayout\">\n\n\n    <h1 {...{\n      \"id\": \"random-forest-regression\"\n    }}>{`Random Forest Regression`}</h1>\n    <h2 {...{\n      \"id\": \"intuition\"\n    }}>{`Intuition`}</h2>\n    <p>{`Random forest is a version of ensemble learning.`}</p>\n    <p>{`It's when you take the same algorithm multiple times and create something more powerful.`}</p>\n    <p><strong parentName=\"p\">{`Steps`}</strong></p>\n    <ol>\n      <li parentName=\"ol\">{`Pick at random K data points from the Training Set.`}</li>\n      <li parentName=\"ol\">{`Build the Decision Tree associated to these K data points.`}</li>\n      <li parentName=\"ol\">{`Choose the number Ntree of trees you want to build and repeat steps 1 and 2.`}</li>\n      <li parentName=\"ol\">{`For a new data point, make each one of your Ntree trees predict the value of `}<inlineCode parentName=\"li\">{`Y`}</inlineCode>{` for the data point in question, and assign the new data point the average across all the predicted `}<inlineCode parentName=\"li\">{`Y`}</inlineCode>{` values.`}</li>\n    </ol>\n    <p>{`Doing this allows you to improve the accuracy of your prediction.`}</p>\n    <p><strong parentName=\"p\">{`Example`}</strong></p>\n    <p>{`How many lollies in a jar? Imagine taking notes of every guess - getting around 1000 and then beginning to average them out or take the median. Statistically speaking, you have a highly likelihood of being closer to the truth.`}</p>\n    <p>{`Once you hit the middle of the normal distribution, you are more likely to be on the money for the guess.`}</p>\n    <h2 {...{\n      \"id\": \"python\"\n    }}>{`PYTHON`}</h2>\n    <p>{`This is the last regression model. If you understand decision tree regression, you'll understand random forest.`}</p>\n    <p>{`From decision tree, we know that we will need the visualisation using the non-continuous result.`}</p>\n    <p>{`For the regressor, we use RandomForestRegressor library.`}</p>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-python\"\n      }}>{`# Prediciting the Random Forest results\n# Create the Regressor\nfrom sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor(random_state=0)\nregressor.fit(X, y)\n`}</code></pre>\n    <p>{`Simply, with these lines, we can already determine that the graph is no longer continuous.`}</p>\n    <p>{`By having several decision trees, we end up with a lot more \"steps\" than we had with just one decision tree.`}</p>\n    <p>{`More tree !== more steps. The more trees you have, the more the average will converge towards the same average.`}</p>\n    <p>{`Generally the steps will become better placed depending on the average.`}</p>\n\n    </MDXLayout>;\n}\n;\nMDXContent.isMDXComponent = true;\n      "],"sourceRoot":""}